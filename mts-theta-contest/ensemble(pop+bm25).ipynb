{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy.sparse as sp\n",
    "from itertools import islice, cycle, product\n",
    "from more_itertools import pairwise\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d67ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/interactions.csv')\n",
    "df_users = pd.read_csv('input/users.csv')\n",
    "df_items = pd.read_csv('input/items.csv')\n",
    "submit = pd.read_csv('input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba7e55",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "### Interaсtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_date']= pd.to_datetime(df.start_date)\n",
    "assert (df.start_date.dt.month.unique() == np.arange(1,13)).all()\n",
    "http://localhost:8888/notebooks/MTC_teta/mts-ml-summer-school/model_ansamble.ipynb#Intera%D1%81tions\n",
    "print(f'df ini.shape: {df.shape}')\n",
    "\n",
    "# если пара пользователь-книга повторяется, то буде использовать мак/мин значения для фичей\n",
    "duplicates = df.duplicated(subset=['user_id', 'item_id'], keep=False)\n",
    "df_duplicates = df[duplicates].sort_values(by=['user_id', 'item_id'])\n",
    "print(f'df_duplicates ini.shape: {df_duplicates.shape}')\n",
    "\n",
    "df = df[~duplicates]\n",
    "\n",
    "df_duplicates = df_duplicates.groupby(['user_id', 'item_id']).agg({\n",
    "                                        'progress': 'max',\n",
    "                                        'rating': 'max',\n",
    "                                        'start_date': 'min'\n",
    "                                        })\n",
    "print(f'df_duplicates after agg.shape: {df_duplicates.shape}')\n",
    "df = df.append(df_duplicates.reset_index(), ignore_index=True)\n",
    "print(f'df.shape: {df.shape}')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed958dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df.rating < 0).sum(), (df.rating > 5).sum())\n",
    "df.rating.fillna(-1).plot(kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating_user_mean'] = df.groupby('user_id').rating.transform(np.mean)\n",
    "df['rating_fillna_user_mean'] = np.where(df.rating.isna(), df.rating_user_mean, df.rating)\n",
    "df.rating_fillna_user_mean.fillna(-1).plot(kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# например, пользователь всем книгам ставит оценку не больше 3, его 3 сопоставима с 5. Уровняем такие разницы вычев среднее по пользователю\n",
    "df['rating_norm_by_user'] = df.rating  - df.groupby('user_id').rating.transform(np.mean)\n",
    "df.rating_norm_by_user.fillna(-5).plot(kind='hist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bae469",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.progress == 0).sum()/ df.shape[0],\\\n",
    "((df.progress == 0) & (df.rating.notna())).sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['progress0_rating_na'] = (df.progress == 0) & (df.rating.notna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df.progress < 0).sum(), (df.progress > 100).sum())\n",
    "df.progress = df.progress.clip(upper=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aca0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92546b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['progress'] = df['progress'].astype(np.int8)\n",
    "df['rating'] = df['rating'].astype(pd.SparseDtype(np.float32, np.nan))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2d10d",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07187085",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_users, df_users.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a86d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3991cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nan_to_cat(df_user, feature):\n",
    "    if df_users[feature].isna().sum() != 0:\n",
    "        df_users[feature] = df_users[feature].astype('category').cat.add_categories(feature+'_nan')\n",
    "        df_users[feature] = df_users[feature].fillna(feature+'_nan')\n",
    "        \n",
    "        \n",
    "def compate_dfs_by_id(df, df_users, feature_id):\n",
    "    interaction_users = df[feature_id].unique()\n",
    "    users = df_users[feature_id].unique()\n",
    "\n",
    "    common_users = len(np.intersect1d(interaction_users, users))\n",
    "    users_only_interaction = len(np.setdiff1d(interaction_users, users))\n",
    "    users_only_features = len(np.setdiff1d(users, interaction_users))\n",
    "    total_users = common_users + users_only_features + users_only_interaction\n",
    "\n",
    "    print(f'Кол-во пользователей - {total_users}')\n",
    "    print(f'Кол-во пользователей cвзаимодействиями и фичами - {common_users} ({common_users / total_users * 100:.2f}%)')\n",
    "    print(f'Кол-во пользователей только c взаимодействиями - {users_only_interaction} ({users_only_interaction / total_users * 100:.2f}%)')\n",
    "    print(f'Кол-во пользователей только c фичами - {users_only_features} ({users_only_features / total_users * 100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compate_dfs_by_id(df, df_users, 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d10985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим пользователей в df_users, если они есть в interection df\n",
    "new_users = np.setdiff1d(df.user_id.unique(), df_users.user_id.unique())\n",
    "df_users = df_users.append(pd.DataFrame(new_users, columns=['user_id']))\n",
    "assert df_users.user_id.nunique() >= df.user_id.nunique()\n",
    "df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.isna().sum()/df_users.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e3589",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_nan_to_cat(df_users, 'age')\n",
    "add_nan_to_cat(df_users, 'sex')\n",
    "df_users.isna().sum(), df_users.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5db06b",
   "metadata": {},
   "source": [
    "### Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f53d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_items.head(), df_items.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.year.value_counts().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_bytes_format(num_bytes, float_prec=4):\n",
    "    units = ['bytes', 'Kb', 'Mb', 'Gb', 'Tb', 'Pb', 'Eb']\n",
    "    for unit in units[:-1]:\n",
    "        if abs(num_bytes) < 1000:\n",
    "            return f'{num_bytes:.{float_prec}f} {unit}'\n",
    "        num_bytes /= 1000\n",
    "    return f'{num_bytes:.4f} {units[-1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bytes = df_items.memory_usage(deep=True).sum()\n",
    "num_bytes_format(num_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.nunique(), df_items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65880b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043005f",
   "metadata": {},
   "source": [
    "### Test/ to_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ebae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_N_DAY = 2 # надо будет предсказать наблюедния за 2 дня, сохраним этот параметр для валидации\n",
    "TOP_N = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8b315",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_FOLDS = 7\n",
    "class TimeRangeSplit():\n",
    "    \"\"\"\n",
    "        https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 start_date, \n",
    "                 end_date=None, \n",
    "                 freq='D', \n",
    "                 periods=None, \n",
    "                 tz=None, \n",
    "                 normalize=False, \n",
    "                 closed=None, \n",
    "                 train_min_date=None,\n",
    "                 filter_cold_users=True, \n",
    "                 filter_cold_items=True, \n",
    "                 filter_already_seen=True):\n",
    "        \n",
    "        self.start_date = start_date\n",
    "        if end_date is None and periods is None:\n",
    "            raise ValueError(\"Either 'end_date' or 'periods' must be non-zero, not both at the same time.\")\n",
    "\n",
    "        self.end_date = end_date\n",
    "        self.freq = freq\n",
    "        self.periods = periods\n",
    "        self.tz = tz\n",
    "        self.normalize = normalize\n",
    "        self.closed = closed\n",
    "        self.train_min_date = pd.to_datetime(train_min_date, errors='raise')\n",
    "        self.filter_cold_users = filter_cold_users\n",
    "        self.filter_cold_items = filter_cold_items\n",
    "        self.filter_already_seen = filter_already_seen\n",
    "\n",
    "        self.date_range = pd.date_range(\n",
    "            start=start_date, \n",
    "            end=end_date, \n",
    "            freq=freq, \n",
    "            periods=periods, \n",
    "            tz=tz, \n",
    "            normalize=normalize, \n",
    "            closed=closed)\n",
    "        \n",
    "        print(self.date_range)\n",
    "\n",
    "        self.max_n_splits = max(0, len(self.date_range) - 1)\n",
    "        if self.max_n_splits == 0:\n",
    "            raise ValueError(\"Provided parametrs set an empty date range.\") \n",
    "\n",
    "    def split(self, \n",
    "              df, \n",
    "              user_column='user_id',\n",
    "              item_column='item_id',\n",
    "              datetime_column='date',\n",
    "              fold_stats=False):\n",
    "        df_datetime = df[datetime_column]\n",
    "        if self.train_min_date is not None:\n",
    "            train_min_mask = df_datetime >= self.train_min_date\n",
    "        else:\n",
    "            train_min_mask = df_datetime.notnull()\n",
    "        date_range = self.date_range[(self.date_range >= df_datetime.min()) & \n",
    "                                     (self.date_range <= df_datetime.max())]\n",
    "        \n",
    "        for start, end in pairwise(date_range):\n",
    "            fold_info = {\n",
    "                'Start date': start,\n",
    "                'End date': end\n",
    "            }\n",
    "            train_mask = train_min_mask & (df_datetime < start)\n",
    "            train_idx = df.index[train_mask]\n",
    "            if fold_stats:\n",
    "                fold_info['Train'] = len(train_idx)\n",
    "\n",
    "            test_mask = (df_datetime >= start) & (df_datetime < end)\n",
    "            test_idx = df.index[test_mask]\n",
    "            \n",
    "            if self.filter_cold_users:\n",
    "                new = np.setdiff1d(\n",
    "                    df.loc[test_idx, user_column].unique(), \n",
    "                    df.loc[train_idx, user_column].unique())\n",
    "                new_idx = df.index[test_mask & df[user_column].isin(new)]\n",
    "                test_idx = np.setdiff1d(test_idx, new_idx)\n",
    "                test_mask = df.index.isin(test_idx)\n",
    "                if fold_stats:\n",
    "                    fold_info['New users'] = len(new)\n",
    "                    fold_info['New users interactions'] = len(new_idx)\n",
    "\n",
    "            if self.filter_cold_items:\n",
    "                new = np.setdiff1d(\n",
    "                    df.loc[test_idx, item_column].unique(), \n",
    "                    df.loc[train_idx, item_column].unique()) # not in train\n",
    "                new_idx = df.index[test_mask & df[item_column].isin(new)]\n",
    "                test_idx = np.setdiff1d(test_idx, new_idx) # in train\n",
    "                test_mask = df.index.isin(test_idx)\n",
    "                if fold_stats:\n",
    "                    fold_info['New items'] = len(new)\n",
    "                    fold_info['New items interactions'] = len(new_idx)\n",
    "\n",
    "            if self.filter_already_seen:\n",
    "                user_item = [user_column, item_column]\n",
    "                train_pairs = df.loc[train_idx, user_item].set_index(user_item).index\n",
    "                test_pairs = df.loc[test_idx, user_item].set_index(user_item).index\n",
    "                intersection = train_pairs.intersection(test_pairs)\n",
    "                test_idx = test_idx[~test_pairs.isin(intersection)] # exclude intersection\n",
    "                if fold_stats:\n",
    "                    fold_info['Known interactions'] = len(intersection)\n",
    "\n",
    "            if fold_stats:\n",
    "                fold_info['Test'] = len(test_idx)\n",
    "\n",
    "            yield (train_idx, test_idx, fold_info)\n",
    "\n",
    "    def get_n_splits(self, df, datetime_column='date'):\n",
    "        df_datetime = df[datetime_column]\n",
    "        if self.train_min_date is not None:\n",
    "            df_datetime = df_datetime[df_datetime >= self.train_min_date]\n",
    "\n",
    "        date_range = self.date_range[(self.date_range >= df_datetime.min()) & \n",
    "                                     (self.date_range <= df_datetime.max())]\n",
    "\n",
    "        return max(0, len(date_range) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('start_date', inplace=True)\n",
    "\n",
    "start_date = df['start_date'].max().normalize() - pd.Timedelta(days=CV_FOLDS) * TEST_N_DAY # количество фолом по 2 дня в каждом\n",
    "cv = TimeRangeSplit(start_date=start_date, periods=CV_FOLDS+1, freq=f'{TEST_N_DAY}d', \n",
    "                    filter_cold_users=False) # в тесте есть новые наблюдения, поэтому для корреляции валидации и теста оставим новые наблюдения в валидации\n",
    "next(cv.split(df, datetime_column='start_date'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754da340",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = list(cv.split(\n",
    "    df, \n",
    "    user_column='user_id',\n",
    "    item_column='item_id',\n",
    "    datetime_column='start_date',\n",
    "    fold_stats=True\n",
    "))\n",
    "\n",
    "folds_info_with_stats = pd.DataFrame([info for _, _, info in cvs])\n",
    "folds_info_with_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb23f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, val_idx, _ in cv.split(df.sort_values('start_date'), datetime_column='start_date'):\n",
    "    train, val = df.loc[train_idx], df.loc[val_idx]\n",
    "    print(train.shape, train.user_id.nunique(), end='\\t')\n",
    "    print(val.shape, val.user_id.nunique(), end='\\n------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.shape, submit.Id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx, _ = cvs[0]\n",
    "train, val = df.loc[train_idx], df.loc[val_idx]\n",
    "\n",
    "print(train.start_date.max(), val.start_date.min())\n",
    "assert folds_info_with_stats['Train'][0] == train.shape[0]\n",
    "assert folds_info_with_stats['Test'][0] == val.shape[0]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4446e3",
   "metadata": {},
   "source": [
    "# Popular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_map(val, recs):\n",
    "    users_count = val.user_id.nunique()\n",
    "\n",
    "    recs = recs.explode('item_id')\n",
    "    recs['rank'] = recs.groupby('user_id').cumcount() + 1\n",
    "\n",
    "    val_recs = val.set_index(['user_id', 'item_id']).join(recs.set_index(['user_id', 'item_id']))\n",
    "    val_recs = val_recs.sort_values(by=['user_id', 'rank'])\n",
    "    val_recs['users_item_count'] = val_recs.groupby(['user_id'], sort=False)['rank'].transform(np.size)\n",
    "\n",
    "    val_recs['cumulative_rank'] = val_recs.groupby(level='user_id').cumcount() + 1\n",
    "    val_recs['cumulative_rank'] = val_recs['cumulative_rank'] / val_recs['rank']\n",
    "\n",
    "    mapN = (val_recs[\"cumulative_rank\"] / val_recs[\"users_item_count\"]).sum() / users_count\n",
    "    print(f\"MAP@{TOP_N} = {mapN}\")\n",
    "    return mapN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3059257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularRecommender():\n",
    "    def __init__(self, max_K=100, days=30, user_column='user_id', item_column='item_id', dt_column='date',\n",
    "                groupby=None, fit_na_as_common=True):\n",
    "        self.max_K = max_K\n",
    "        self.days = days\n",
    "        self.user_column = user_column\n",
    "        self.item_column = item_column\n",
    "        self.dt_column = dt_column\n",
    "        self.groupby = groupby\n",
    "        self.fit_na_as_common = fit_na_as_common\n",
    "        self.recommendations = []\n",
    "        \n",
    "    def fit(self, df, df_users=None):\n",
    "        min_date = df[self.dt_column].max().normalize() - pd.DateOffset(days=self.days)\n",
    "        data = df[df[self.dt_column] > min_date]\n",
    "        recomm_common = data[self.item_column].value_counts().head(self.max_K).index.values\n",
    "        self.recomm_common = recomm_common\n",
    "        self.df_users = df_users\n",
    "        \n",
    "        if self.groupby is not None:\n",
    "            if df_users is None:\n",
    "                print('No df_users')\n",
    "                return None\n",
    "            \n",
    "            data = data.merge(df_users, on=self.user_column, how='left')\n",
    "            self.recommendations = data.groupby(self.groupby)[self.item_column]\\\n",
    "                                       .apply(lambda x: x.value_counts().head(self.max_K).index.values)\n",
    "            # если нет записей для рекомендации, рекомендовать общее\n",
    "            na_mask = self.recommendations.isna()\n",
    "            self.recommendations[na_mask] = self.recommendations[na_mask].apply(lambda x: recomm_common)\n",
    "            # на случай, если список рекомендаций будет коротким (например только 2 книги)\n",
    "            # добавим общую рекоменацию\n",
    "            self.recommendations = self.recommendations.apply(lambda x: np.concatenate((x, recomm_common)))\n",
    "            # na в категориях\n",
    "            if self.fit_na_as_common:\n",
    "                na_mask = (self.recommendations.reset_index()[self.groupby]=='nan').sum(axis=1)!=0\n",
    "                self.recommendations[na_mask.values] = self.recommendations[na_mask.values].apply(lambda x: recomm_common)\n",
    "        else:\n",
    "            self.recommendations = recomm_common\n",
    "        \n",
    "    def recommend(self, users=None, N=10):\n",
    "        recs = self.recommendations[:N]\n",
    "        \n",
    "        if users is None:\n",
    "            if self.groupby is not None:\n",
    "                print('For recomendations based on groupby needs used_id')\n",
    "                return None\n",
    "            return recs\n",
    "        else:\n",
    "            if self.groupby is not None:\n",
    "                recoms = self.recommendations.apply(lambda x: x[:N]) # только N первых рекомендаций\n",
    "                recoms = recoms.reset_index()\n",
    "                recoms[self.groupby] = recoms[self.groupby].astype('category')\n",
    "                data = users.to_frame().merge(self.df_users, on=self.user_column, how='left') # добавляем информацию по пользователям для разбиения на группы\n",
    "                data = data.merge(recoms, on=self.groupby, how='left') # добавляем рекомендации в соответсвии с группой\n",
    "                # если встречается уникальная группа, то пресказания будут пропусками. Заполнить их общими предсказаниями по всему набору\n",
    "                na_mask = data.iloc[:, -1].isna()\n",
    "                data.iloc[:, -1][na_mask] = data.iloc[:, -1][na_mask].apply(lambda x: self.recomm_common[:N])\n",
    "\n",
    "                return data.iloc[:, -1].values.tolist()\n",
    "            \n",
    "            else: # если не было разбиения на группы\n",
    "                return list(islice(cycle([recs]), len(users))) # возвращаем общее предсказание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4886a",
   "metadata": {},
   "source": [
    "## Cross-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a723e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Popular_cv(model):\n",
    "    metrics = []\n",
    "    for train_idx, val_idx, _ in cvs:\n",
    "        train, val = df.loc[train_idx], df.loc[val_idx]\n",
    "\n",
    "        model.fit(train, df_users)\n",
    "\n",
    "        recs = pd.DataFrame({'user_id': val['user_id'].unique()})\n",
    "        recs['item_id'] = model.recommend(recs['user_id'], N=TOP_N)\n",
    "\n",
    "        metrics.append(metrics_map(val, recs))\n",
    "\n",
    "    map_mean = np.mean(metrics)\n",
    "    print(f'mean MAP@10 = {map_mean}')\n",
    "    print(f'std MAP@10 = {np.std(metrics)}')\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def model_Popular_to_submit(model, name=''):\n",
    "    model.fit(df, df_users)\n",
    "\n",
    "    user_id = submit['Id'].copy()\n",
    "    user_id.rename('user_id',inplace=True)\n",
    "    recs = model.recommend(user_id, N=TOP_N)\n",
    "    submit['Predicted'] = recs\n",
    "    submit['Predicted'] = submit.Predicted.apply(lambda x: ' '.join(map(str, x)) if x is not np.nan else '')\n",
    "    submit.to_csv(f'submit{name}.csv', index=False)\n",
    "    return submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65217c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e465eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for days in tqdm(range(21, 33)):\n",
    "#     params['days'] = days\n",
    "#     model = PopularRecommender(**params)\n",
    "#     metrics = model_Popular_cv(model, temp, drop_known=True)\n",
    "#     to_add = dict(days=days, \n",
    "#                   map_mean = np.mean(metrics),\n",
    "#                   map_std=np.std(metrics))\n",
    "#     results.append(to_add)\n",
    "    \n",
    "# pd.DataFrame(results).sort_values('map_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(groupby=None,\n",
    "              fit_na_as_common=False,\n",
    "              days = 21)\n",
    "\n",
    "model = PopularRecommender(dt_column='start_date', \n",
    "                           **params)\n",
    "metrics = model_Popular_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94697f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PopularRecommender(days= 21 , groupby=['genre'], dt_column='start_date')\n",
    "model.fit(df, df_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0f828",
   "metadata": {},
   "source": [
    "## BM25Recommender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91176b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_inv_mapping = dict(enumerate(df['user_id'].unique()))\n",
    "users_mapping = {v: k for k, v in users_inv_mapping.items()}\n",
    "\n",
    "items_inv_mapping = dict(enumerate(df['item_id'].unique()))\n",
    "items_mapping = {v: k for k, v in items_inv_mapping.items()}\n",
    "\n",
    "item_titles = pd.Series(df_items['title'].values, index=df_items['id']).to_dict()\n",
    "\n",
    "len(users_mapping), len(items_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coo_matrix(df, \n",
    "                   user_col='user_id', \n",
    "                   item_col='item_id', \n",
    "                   weight_col=None, \n",
    "                   users_mapping=users_mapping, \n",
    "                   items_mapping=items_mapping):\n",
    "    if weight_col is None:\n",
    "        weights = np.ones(len(df), dtype=np.float32)\n",
    "    else:\n",
    "        weights = df[weight_col].astype(np.float32)\n",
    "\n",
    "    interaction_matrix = sp.coo_matrix((\n",
    "        weights, \n",
    "        (\n",
    "            df[user_col].map(users_mapping.get), \n",
    "            df[item_col].map(items_mapping.get)\n",
    "        )\n",
    "    ))\n",
    "    return interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = get_coo_matrix(train).tocsr()\n",
    "assert train_mat.shape == (train['user_id'].map(users_mapping.get).max()+1,\n",
    "                    train['item_id'].map(items_mapping.get).max()+1)\n",
    "train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = get_coo_matrix(df).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import BM25Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d136c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BM25Recommender(K=10)\n",
    "model.fit(mat.T) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de423cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для новых наблюдений будем использовать общепопулярную рекомендацию, без группировки соотвественно\n",
    "pop_model = PopularRecommender(days=21, dt_column='start_date')\n",
    "pop_model.fit(df, df_users)\n",
    "recomm_mapper = pop_model.recomm_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_implicit_recs_mapper(model, train_matrix, N, user_mapping, item_inv_mapping, recomm_mapper, thres=20):\n",
    "    def _recs_mapper(user):\n",
    "        try:\n",
    "            user_id = user_mapping[user]\n",
    "        except KeyError:\n",
    "            return recomm_mapper[:N]\n",
    "        if user in user_to_lib.keys() and len(user_to_lib[user]) < thres:\n",
    "            return recomm_mapper[:N]\n",
    "        if user_id >= train_matrix.shape[0]:\n",
    "            return recomm_mapper[:N]\n",
    "        else:\n",
    "            recs = model.recommend(user_id, \n",
    "                               train_matrix, \n",
    "                               N=N, \n",
    "                               filter_already_liked_items=True)\n",
    "        return [item_inv_mapping[item] for item, _ in recs]\n",
    "    return _recs_mapper\n",
    "\n",
    "def generate_implicit_recs_mapper_submit(model, train_matrix, N, user_mapping, item_inv_mapping, recomm_mapper, thres=20):\n",
    "    def _recs_mapper(user):\n",
    "        try:\n",
    "            user_id = user_mapping[user]\n",
    "        except KeyError:\n",
    "            return recomm_mapper[:N]\n",
    "        if user in user_to_lib.keys() and len(user_to_lib[user]) < thres:\n",
    "            return recomm_mapper[:N]\n",
    "        if user_id >= train_matrix.shape[0]:\n",
    "            return recomm_mapper[:N]\n",
    "        else:\n",
    "            recs = model.recommend(user_id, \n",
    "                               train_matrix, \n",
    "                               N=N, \n",
    "                               filter_already_liked_items=True)\n",
    "        return [item_inv_mapping[item] for item, _ in recs]\n",
    "    return _recs_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf391826",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = generate_implicit_recs_mapper(model, mat, 10, \n",
    "                                       users_mapping, items_inv_mapping, recomm_mapper, thres=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4419ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Predicted'] = submit['Id'].map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d49bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Predicted'] = submit.Predicted.apply(lambda x: ' '.join(map(str, x)) if x is not np.nan else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49210b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
